{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/ElegantRL/blob/master/tutorial_BipedalWalker_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1gUG3OCJ5GS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **BipedalWalker-v3 Example in ElegantRL**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGXyBBvL0dR2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Task Description**\n",
    "\n",
    "[BipedalWalker-v3](https://gym.openai.com/envs/BipedalWalker-v2/) is a robotic task in OpenAI Gym since it performs one of the most fundamental skills: moving. In this task, our goal is to get a 2D bipedal walker to walk through rough terrain. BipedalWalker is a difficult task in continuous action space, and there are only a few RL implementations can reach the target reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbamGVHC3AeW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Part 1: Install ElegantRL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U35bhkUqOqbS",
    "outputId": "79ace170-9a20-46cd-db96-957fd42a472f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/ElegantRL.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/ElegantRL.git to c:\\users\\zdl\\appdata\\local\\temp\\pip-req-build-mpcq43o4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/AI4Finance-LLC/ElegantRL.git 'C:\\Users\\zdl\\AppData\\Local\\Temp\\pip-req-build-mpcq43o4'\n",
      "  ERROR: Error [WinError 2] 系统找不到指定的文件。 while executing command git clone -q https://github.com/AI4Finance-LLC/ElegantRL.git 'C:\\Users\\zdl\\AppData\\Local\\Temp\\pip-req-build-mpcq43o4'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "# install elegantrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/ElegantRL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVdmpnK_3Zcn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Part 2: Import Packages**\n",
    "\n",
    "\n",
    "*   **elegantrl**\n",
    "*   **OpenAI Gym**: a toolkit for developing and comparing reinforcement learning algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AAPdjovQrTpE",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3676569566.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [2]\u001b[1;36m\u001b[0m\n\u001b[1;33m    import gymfrom elegantrl.agents import AgentPPOfrom elegantrl.train.config import get_gym_env_args, Argumentsfrom elegantrl.train.run import *\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import gymfrom elegantrl.agents import AgentPPOfrom elegantrl.train.config import get_gym_env_args, Argumentsfrom elegantrl.train.run import *\n",
    "\n",
    "gym.logger.set_level(40) # Block warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2Ik5cDoyPGU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Part 3: Get environment information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwkZXiHtyV6f",
    "outputId": "880d25f5-d1f0-4cd2-8f78-bb5409330101",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_gym_env_args(gym.make(\"BipedalWalker-v3\"), if_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n8zcgcn14uq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Part 4: Specify Agent and Environment**\n",
    "\n",
    "*   **agent**: chooses a agent (DRL algorithm) from a set of agents in the [directory](https://github.com/AI4Finance-Foundation/ElegantRL/tree/master/elegantrl/agents).\n",
    "*   **env_func**: the function to create an environment, in this case, we use gym.make to create BipedalWalker-v3.\n",
    "*   **env_args**: the environment information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E03f6cTeajK4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env_func \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mmake\n\u001b[0;32m      2\u001b[0m env_args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_num\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBipedalWalker-v3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBipedalWalker-v3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     12\u001b[0m args \u001b[38;5;241m=\u001b[39m Arguments(AgentPPO, env_func\u001b[38;5;241m=\u001b[39menv_func, env_args\u001b[38;5;241m=\u001b[39menv_args)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "env_func = gym.make\n",
    "env_args = {\n",
    "    \"env_num\": 1,\n",
    "    \"env_name\": \"BipedalWalker-v3\",\n",
    "    \"max_step\": 1600,\n",
    "    \"state_dim\": 24,\n",
    "    \"action_dim\": 4,\n",
    "    \"if_discrete\": False,\n",
    "    \"target_return\": 300,\n",
    "    \"id\": \"BipedalWalker-v3\",\n",
    "}\n",
    "args = Arguments(AgentPPO, env_func=env_func, env_args=env_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcFcUkwfzHLE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Part 4: Specify hyper-parameters**\n",
    "A list of hyper-parameters is available [here](https://elegantrl.readthedocs.io/en/latest/api/config.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9WCAcmIfzGyE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m args\u001b[38;5;241m.\u001b[39mtarget_step \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mmax_step \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m      2\u001b[0m args\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.98\u001b[39m\n\u001b[0;32m      3\u001b[0m args\u001b[38;5;241m.\u001b[39meval_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "args.target_step = args.max_step * 4\n",
    "args.gamma = 0.98\n",
    "args.eval_times = 2**4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1j5kLHF2dhJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Part 5: Train and Evaluate the Agent**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGOPSD6da23k",
    "outputId": "2a8ed03b-b306-45f8-c530-adf72438c5bd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_and_evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m(args)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_and_evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPXOxLSqh5cP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Understanding the above results::\n",
    "*   **Step**: the total training steps.\n",
    "*  **MaxR**: the maximum reward.\n",
    "*   **avgR**: the average of the rewards.\n",
    "*   **stdR**: the standard deviation of the rewards.\n",
    "*   **objA**: the objective function value of Actor Network (Policy Network).\n",
    "*   **objC**: the objective function value (Q-value)  of Critic Network (Value Network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "tutorial_BipedalWalker-v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
